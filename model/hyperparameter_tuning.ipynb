{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "# initialize data for hyperparameter tuning\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import html\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow import string\n",
    "from tensorflow_hub import KerasLayer\n",
    "\n",
    "psy = pd.read_csv('datasets/Youtube01-Psy.csv')\n",
    "katy_perry = pd.read_csv('datasets/Youtube02-KatyPerry.csv')\n",
    "lmfao = pd.read_csv('datasets/Youtube03-LMFAO.csv')\n",
    "eminem = pd.read_csv('datasets/Youtube04-Eminem.csv')\n",
    "shakira = pd.read_csv('datasets/Youtube05-Shakira.csv')\n",
    "df_1 = pd.concat([psy, katy_perry, lmfao, eminem, shakira], ignore_index=True)\n",
    "df_1 = df_1[['CONTENT', 'CLASS']]\n",
    "df_1 = df_1.rename(columns={'CONTENT': 'comment', 'CLASS': 'target'})\n",
    "df_2 = pd.read_csv('datasets/comments_1.csv')\n",
    "df_2 = df_2[['Comment', 'Spam']]\n",
    "df_2 = df_2.rename(columns={'Comment': 'comment', 'Spam': 'target'})\n",
    "df = pd.concat([df_1, df_2], ignore_index=True)\n",
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def pre_process(text):\n",
    "    html_entities_removed = html.unescape(text.lower())\n",
    "    html_tags_removed = re.sub('<.*?>', ' ', html_entities_removed)\n",
    "    link_keywords = re.sub(r'(?<=(http|[wW]{3}))\\S+', ' ', html_tags_removed)\n",
    "    nonlatin_chars_removed = re.sub(r'[^A-Za-z\\s]+', '  ', link_keywords)\n",
    "    tokenized = word_tokenize(nonlatin_chars_removed)\n",
    "    stopwords_removed = [word for word in tokenized if not word in en_stopwords]\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in stopwords_removed]\n",
    "    output = ' '.join(lemmatized)\n",
    "    return output\n",
    "\n",
    "df['cleaned'] = df['comment'].apply(pre_process)\n",
    "df = df.replace('', float('NaN')).dropna().drop_duplicates()\n",
    "X = df['cleaned'].values\n",
    "y = df['target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "Layers (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n",
      "Hidden Layers (Choice)\n",
      "{'default': 17, 'conditions': [], 'values': [17, 40, 61], 'ordered': True}\n",
      "Learning Rate (Choice)\n",
      "{'default': 0.0005, 'conditions': [], 'values': [0.0005, 0.00075, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(KerasLayer('nnlm_en_dim50_2', input_shape=[], dtype=string, trainable=True))\n",
    "\tmodel.add(Reshape((1,50)))\n",
    "\tmodel.add(SimpleRNN(hp.Choice('Layers',[32,64,128])))\n",
    "\tmodel.add(Dense(hp.Choice('Hidden Layers',[17,40,61]), activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=Adam(learning_rate=hp.Choice('Learning Rate', [0.0005, 0.00075, 0.001])),\n",
    "\t\tloss='binary_crossentropy', metrics=['accuracy']\n",
    "\t)\n",
    "\treturn model\n",
    "\n",
    "build_model(kt.HyperParameters())\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "\thypermodel=build_model,\n",
    "\tobjective='val_loss',\n",
    "\tmax_trials=300,\n",
    "\tseed=42,\n",
    "\tdirectory='hyperparameter_tuning',\n",
    "\tproject_name='ytcs'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 Complete [00h 00m 31s]\n",
      "val_loss: 0.25419744849205017\n",
      "\n",
      "Best val_loss So Far: 0.23909778892993927\n",
      "Total elapsed time: 00h 14m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparameter_tuning\\ytcs\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000002D09779BCD0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 32\n",
      "Hidden Layers: 40\n",
      "Learning Rate: 0.00075\n",
      "Score: 0.23909778892993927\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 32\n",
      "Hidden Layers: 40\n",
      "Learning Rate: 0.0005\n",
      "Score: 0.24265210330486298\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 32\n",
      "Hidden Layers: 40\n",
      "Learning Rate: 0.001\n",
      "Score: 0.24302244186401367\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 64\n",
      "Hidden Layers: 40\n",
      "Learning Rate: 0.001\n",
      "Score: 0.24554672837257385\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 64\n",
      "Hidden Layers: 40\n",
      "Learning Rate: 0.00075\n",
      "Score: 0.24828709661960602\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 32\n",
      "Hidden Layers: 61\n",
      "Learning Rate: 0.00075\n",
      "Score: 0.2494523823261261\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 64\n",
      "Hidden Layers: 17\n",
      "Learning Rate: 0.0005\n",
      "Score: 0.2509346008300781\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 32\n",
      "Hidden Layers: 61\n",
      "Learning Rate: 0.001\n",
      "Score: 0.25227946043014526\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 64\n",
      "Hidden Layers: 61\n",
      "Learning Rate: 0.00075\n",
      "Score: 0.25419744849205017\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "Layers: 128\n",
      "Hidden Layers: 17\n",
      "Learning Rate: 0.001\n",
      "Score: 0.2545337677001953\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 50)                48190600  \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 1, 50)             0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 32)                2656      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 40)                1320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,194,617\n",
      "Trainable params: 48,194,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(tuner.get_best_hyperparameters()[0])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "921a9f4eb1b92f7c45465ac512b7e65f267dfc6f92c15eb890e7adb4e74bdac0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
